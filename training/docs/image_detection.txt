# PyTorch Pokémon Classification on 7K Images with Augmentation and Model Comparison

import os
import glob
import torch
import torch.nn as nn
import torch.optim as optim
import torchvision.transforms as transforms
from torch.utils.data import Dataset, DataLoader
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, ConfusionMatrixDisplay
import pandas as pd
import numpy as np
from PIL import Image
import matplotlib.pyplot as plt
from torchvision.models import resnet18, densenet121, ResNet18_Weights, DenseNet121_Weights
import random

# --- Config ---
BATCH_SIZE = 64
IMG_SIZE = 128
EPOCHS = 12
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# --- Load Data Using Directory Structure ---
directory = "/kaggle/input/pokemonclassification/PokemonData"
labels = sorted(os.listdir(directory))
label_to_idx = {label: idx for idx, label in enumerate(labels)}
idx_to_label = {idx: label for label, idx in label_to_idx.items()}

image_paths = []
image_labels = []

for label in labels:
    folder = os.path.join(directory, label)
    for file in os.listdir(folder):
        if file.endswith(".png") or file.endswith(".jpg"):
            image_paths.append(os.path.join(folder, file))
            image_labels.append(label_to_idx[label])

X = np.array(image_paths)
y = np.array(image_labels)

# --- Train-Test Split ---
train_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

# --- Transforms ---
train_transform = transforms.Compose([
    transforms.Resize((IMG_SIZE + 10, IMG_SIZE + 10)),
    transforms.RandomCrop(IMG_SIZE),
    transforms.RandomHorizontalFlip(),
    transforms.RandomRotation(15),
    transforms.ColorJitter(brightness=0.3, contrast=0.3),
    transforms.ToTensor()
])

test_transform = transforms.Compose([
    transforms.Resize((IMG_SIZE, IMG_SIZE)),
    transforms.ToTensor()
])

# --- Dataset Class ---
class PokemonDataset(Dataset):
    def __init__(self, image_paths, labels, transform=None):
        self.image_paths = image_paths
        self.labels = torch.tensor(labels, dtype=torch.long)
        self.transform = transform

    def __len__(self):
        return len(self.image_paths)

    def __getitem__(self, idx):
        image = Image.open(self.image_paths[idx]).convert('RGB')
        if self.transform:
            image = self.transform(image)
        return image, self.labels[idx], self.image_paths[idx]

train_dataset = PokemonDataset(train_X, train_y, transform=train_transform)
test_dataset = PokemonDataset(test_X, test_y, transform=test_transform)
train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)

# --- Model Architectures ---
class SimpleCNN(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        self.model = nn.Sequential(
            nn.Conv2d(3, 32, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Conv2d(32, 64, 3, padding=1), nn.ReLU(), nn.MaxPool2d(2),
            nn.Flatten(),
            nn.Linear(64 * (IMG_SIZE // 4) * (IMG_SIZE // 4), 128), nn.ReLU(),
            nn.Linear(128, num_classes)
        )

    def forward(self, x):
        return self.model(x)

class PretrainedResNet18(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        self.model = resnet18(weights=ResNet18_Weights.DEFAULT)
        for param in self.model.parameters():
            param.requires_grad = False
        self.model.fc = nn.Linear(self.model.fc.in_features, num_classes)

    def forward(self, x):
        return self.model(x)

class PretrainedDenseNet(nn.Module):
    def __init__(self, num_classes):
        super().__init__()
        self.model = densenet121(weights=DenseNet121_Weights.DEFAULT)
        for param in self.model.features.parameters():
            param.requires_grad = False
        self.model.classifier = nn.Linear(self.model.classifier.in_features, num_classes)

    def forward(self, x):
        return self.model(x)

models = {
    "SimpleCNN": SimpleCNN(len(labels)),
    "ResNet18": PretrainedResNet18(len(labels)),
    "DenseNet121": PretrainedDenseNet(len(labels))
}

results = {}
best_model = None
best_acc = 0

# --- Train & Evaluate ---
def train_and_evaluate(model, name):
    global best_model, best_acc
    model.to(DEVICE)
    optimizer = optim.Adam(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)
    criterion = nn.CrossEntropyLoss()

    for epoch in range(EPOCHS):
        model.train()
        total_loss = 0
        for images, labels, _ in train_loader:
            images, labels = images.to(DEVICE), labels.to(DEVICE)
            optimizer.zero_grad()
            outputs = model(images)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()
            total_loss += loss.item()
        print(f"[{name}] Epoch {epoch+1}/{EPOCHS} - Loss: {total_loss / len(train_loader):.4f}")

    model.eval()
    preds, targets = [], []
    with torch.no_grad():
        for images, labels, _ in test_loader:
            outputs = model(images.to(DEVICE))
            preds.extend(torch.argmax(outputs, dim=1).cpu().numpy())
            targets.extend(labels.cpu().numpy())

    acc = accuracy_score(targets, preds)
    f1 = f1_score(targets, preds, average='weighted')
    cm = confusion_matrix(targets, preds)
    print(f"Test Accuracy ({name}): {acc * 100:.2f}%")
    print(f"F1 Score ({name}): {f1 * 100:.2f}%")

    # Confusion matrix display removed to avoid FixedLocator issue

    # Save best model
    if acc > best_acc:
        best_model = model
        best_acc = acc
        torch.save(model.state_dict(), f"best_model_{name}.pth")

    # Display sample predictions
    print("\nSample Predictions:")
    sample_indices = random.sample(range(len(test_dataset)), 5)
    model.eval()
    for idx in sample_indices:
        image, label, path = test_dataset[idx]
        with torch.no_grad():
            output = model(image.unsqueeze(0).to(DEVICE))
            pred = torch.argmax(output, dim=1).item()
        plt.imshow(Image.open(path))
        plt.title(f"True: {idx_to_label[label.item()]}, Pred: {idx_to_label[pred]}")
        plt.axis('off')
        plt.show()

    results[name] = acc

# --- Run Models ---
for name, model in models.items():
    train_and_evaluate(model, name)

# --- Visualize Results ---
plt.figure(figsize=(8, 4))
plt.bar(results.keys(), [v * 100 for v in results.values()], color='lightgreen')
plt.ylabel('Test Accuracy (%)')
plt.title('Pokémon Type1 Classification - Model Comparison')
plt.ylim(0, 100)
plt.grid(axis='y')
plt.show()

