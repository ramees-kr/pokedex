# PokÃ©mon Image Classifier with Streamlit PokÃ©dex

## ğŸ” Objective

This project aims to build and deploy a deep learning-based image classification application using PyTorch and Streamlit. The application identifies PokÃ©mon from images and displays relevant PokÃ©dex information interactively.

## âœ¨ Features

- **Image Classification:** Identifies PokÃ©mon species from provided test images.
- **Model Selection:** Allows users to choose between different trained deep learning models for inference (SimpleCNN, ResNet18, DenseNet121, MobileNetV2).
- **Interactive Interface:** Built with Streamlit, featuring:
  - A left sidebar for configuration (model and image selection).
  - A main panel displaying the selected image and the prediction results (predicted PokÃ©mon name and confidence score).
  - A right panel displaying PokÃ©dex information (type, base stats, description) for the predicted PokÃ©mon.
- **PokÃ©dex Integration:** Fetches and displays data for the predicted PokÃ©mon from a `pokedex.json` file.

## ğŸ“¸ Demo / Screenshots

_(Placeholder: Add screenshots of your Streamlit application here)_

- _Screenshot of the main interface_
- _Screenshot showing model selection_
- _Screenshot showing PokÃ©dex info_

## ğŸ“ Project Structure

The project follows this directory structure:

```
pokemon_recognition/
â”œâ”€â”€ app.py                 # Main Streamlit application script
â”œâ”€â”€ class_names.txt        # List of PokÃ©mon class names for the model
â”œâ”€â”€ pokedex.json           # PokÃ©mon metadata file
â”œâ”€â”€ requirements.txt       # Python dependencies
â”œâ”€â”€ .gitignore             # Git ignore rules
â”œâ”€â”€ models/                # Folder containing trained model weights (.pth files)
â”‚   â”œâ”€â”€ best_model_SimpleCNN.pth
â”‚   â”œâ”€â”€ best_model_ResNet18.pth
â”‚   â”œâ”€â”€ best_model_DenseNet121.pth
â”‚   â””â”€â”€ best_model_MobileNetV2.pth
â”œâ”€â”€ test_images/           # Folder containing sample images for testing
â”‚   â”œâ”€â”€ Pikachu_abc123.jpg
â”‚   â””â”€â”€ ...
â”œâ”€â”€ .venv/                 # Virtual environment folder (if used)
â”œâ”€â”€ Streamlit_Application_Plan.txt # Original planning document
â””â”€â”€ Training_Models_Plan.txt # Original training documentation
```

_(Note: Model file names in `models/` might vary slightly based on your saving convention)_

## ğŸ§  Models

Several Convolutional Neural Network (CNN) models were trained for classification:

- **SimpleCNN:** A basic custom CNN architecture.
- **ResNet18:** Pretrained ResNet18 with transfer learning.
- **DenseNet121:** Pretrained DenseNet121 with transfer learning (identified as the best performing model in initial tests).
- **MobileNetV2:** Pretrained MobileNetV2 with transfer learning.

**Training Details:**

- **Dataset:** Trained on a dataset of approximately 7,000 labeled PokÃ©mon images, structured by class folders (e.g., `PokemonData/Pikachu/`). Dataset sourced from Kaggle: [PokÃ©mon Classification Dataset](https://www.kaggle.com/datasets/lantian773030/pokemonclassification/data).
- **Preprocessing:** Images resized to 128x128 pixels. Training included augmentations like random crops, flips, rotation, and color jitter. Inference uses resizing and tensor conversion.
- **Framework:** PyTorch.
- **Training:** Models were trained for 12 epochs.

## ğŸ“Š Data Sources

- **PokÃ©mon Image Dataset:** Sourced from Kaggle: [PokÃ©mon Classification Dataset](https://www.kaggle.com/datasets/lantian773030/pokemonclassification/data) (Approx. 7,000 images across 150+ classes).
- **PokÃ©dex Data:** `pokedex.json` obtained from a public source: [Purukitto/pokemon-data.json](https://github.com/Purukitto/pokemon-data.json/blob/master/pokedex.json).

## ğŸ› ï¸ Setup & Installation

1.  **Clone the repository (if applicable):**
    ```bash
    git clone https://github.com/ramees-kr/pokedex.git
    cd pokemon_recognition
    ```
2.  **Create and activate a virtual environment (Recommended):**
    ```bash
    python -m venv .venv
    # On Windows
    .\.venv\Scripts\activate
    # On macOS/Linux
    source .venv/bin/activate
    ```
3.  **Install dependencies:**

    ```bash
    pip install -r requirements.txt
    ```

4.  **Ensure you have the necessary data files:**
    - `class_names.txt` in the root directory.
    - `pokedex.json` in the root directory.
    - Trained model `.pth` files inside the `models/` directory.
    - Sample images inside the `test_images/` directory.

## ğŸš€ Running the Application

1.  **Activate your virtual environment** (if not already active):
    ```bash
    # On Windows
    .\.venv\Scripts\activate
    # On macOS/Linux
    source .venv/bin/activate
    ```
2.  **Run the Streamlit app:**

    ```bash
    streamlit run app.py --server.fileWatcherType none
    ```

3.  The application should open in your web browser automatically.

## ğŸ“‹ Usage

1.  Use the **left sidebar** to select the classification model you want to use from the dropdown menu.
2.  Use the second dropdown in the left sidebar to choose a PokÃ©mon image from the `test_images/` folder. A preview will appear below.
3.  The **main panel** will display the selected image and the model's prediction (PokÃ©mon name and confidence score).
4.  The **right panel** will automatically display PokÃ©dex information (Type, Stats, Description) for the predicted PokÃ©mon, if available in the `pokedex.json` file.

## ğŸ’¡ Future Enhancements

Potential improvements and future steps for this project include:

- Implementing drag-and-drop image upload for user-provided images.
- Adding real-time prediction capabilities using webcam input.
- Enhancing the `pokedex.json` file with more detailed descriptions or PokÃ©mon sprites/images.
- Deploying the application to a platform like Streamlit Cloud or Hugging Face Spaces.
- Visualizing confidence scores for the top predicted classes (e.g., using a bar chart).

## ğŸ™ Acknowledgements

- Thanks to the creators of the PokÃ©mon image dataset and the PokÃ©dex JSON data.
- Built using PyTorch and Streamlit.
